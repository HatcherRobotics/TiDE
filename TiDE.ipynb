{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于每个时刻的协变量，将其特征维度由r映射到远小于r的r_bar\n",
    "class FeatureProjection(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,dropout_prob):\n",
    "        super().__init__()\n",
    "        self.dense_relu = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense_linear = nn.Linear(hidden_size,output_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        y = self.dense_relu(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.dense_linear(y)\n",
    "        y = self.dropout(y)\n",
    "        x = self.linear(x)\n",
    "        y = y+x\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseEncoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,dropout_prob,num_block) :\n",
    "        super().__init__()\n",
    "        self.first_block =  FeatureProjection(input_size,hidden_size,hidden_size,dropout_prob)\n",
    "        self.mid_block =  FeatureProjection(hidden_size,hidden_size,hidden_size,dropout_prob)\n",
    "        self.last_block = FeatureProjection(hidden_size,hidden_size,output_size,dropout_prob)\n",
    "        self.one_block = FeatureProjection(input_size,hidden_size,output_size,dropout_prob)\n",
    "        self.num_block = num_block\n",
    "    def forward(self,x):\n",
    "        if(self.num_block==1):\n",
    "            y = self.one_block(x)\n",
    "            return y\n",
    "        elif(self.num_block==2):\n",
    "            y = self.first_block(x)\n",
    "            y = self.last_block(y)\n",
    "            return y\n",
    "        else:\n",
    "            y = self.first_block(x)\n",
    "            for i in range(self.num_block-2):\n",
    "                y = self.mid_block(y)\n",
    "            y = self.last_block(y)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p X H\n",
    "#第t列代表预测的时刻t的特征向量，p维 \n",
    "class DenseDecoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,H,p,dropout_prob,num_block) :\n",
    "        super().__init__()\n",
    "        self.first_block =  FeatureProjection(input_size,hidden_size,hidden_size,dropout_prob)\n",
    "        self.mid_block =  FeatureProjection(hidden_size,hidden_size,hidden_size,dropout_prob)\n",
    "        self.output_size = H*p\n",
    "        self.last_block = FeatureProjection(hidden_size,hidden_size,self.output_size,dropout_prob)\n",
    "        self.one_block = FeatureProjection(input_size,hidden_size,self.output_size,dropout_prob)\n",
    "        self.num_block = num_block\n",
    "        self.H = H\n",
    "        self.p = p\n",
    "    def forward(self,x):\n",
    "        if(self.num_block==1):\n",
    "            y = self.one_block(x)\n",
    "        elif(self.num_block==2):\n",
    "            y = self.first_block(x)\n",
    "            y = self.last_block(y)\n",
    "        else:\n",
    "            y = self.first_block(x)\n",
    "            for i in range(self.num_block-2):\n",
    "                y = self.mid_block(y)\n",
    "            y = self.last_block(y)\n",
    "            batch_size = y.shape[0]\n",
    "        y = torch.reshape(y,(batch_size,self.p,self.H))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalDecoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,dropout_prob):\n",
    "        super().__init__()\n",
    "        self.decoder = FeatureProjection(input_size,hidden_size,1,dropout_prob)\n",
    "    def forward(self,x):\n",
    "        y = self.decoder(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size seq_length feature_size\n",
    "class TiDE(nn.Module):\n",
    "    def __init__(self,temporalWidth,hiddenSize,numEncoderLayers,H,decoderOutputDim,numDecoderLayers,temporalDecoderHidden,y_position=0,attrib_position=1):\n",
    "        self.attrib_position = attrib_position\n",
    "        self.y_position = y_position\n",
    "        self.temporalWidth = temporalWidth#r_bar\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numEncoderLayers = numEncoderLayers\n",
    "        self.H = H\n",
    "        self.decoderOutputDim = decoderOutputDim#p\n",
    "        self.numDecoderLayers = numDecoderLayers\n",
    "        self.temporalDecoderHidden = temporalDecoderHidden\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0];\n",
    "        seq_length = x.shape[1];\n",
    "        feature_size = x.shape[2];\n",
    "        y_lookback = x[:,:,self.y_position]#batch_size seq_length 1\n",
    "        a = x[:,:,self.attrib_position]#batch_size seq_length 1\n",
    "        x = x[:,2:,:]#batch_size seq_length feature_size-2\n",
    "        #把特征维度压缩至r_bar\n",
    "        feature_projection = FeatureProjection(feature_size,(feature_size+self.temporalWidth)//2,self.temporalWidth,0.2)\n",
    "        for i in range(x.shape[1]):#batch_size 1 r_bar\n",
    "            if(i==0):\n",
    "                x_bar = feature_projection(x[:,i,:].squeeze()).unsqueeze(dim=1)\n",
    "            else:\n",
    "                x_bar = x_bar.concat(feature_projection(x[:,i,:].squeeze()).unsqueeze(dim=1),dim=1)\n",
    "            \n",
    "        #x_bar batch_size seq_length temporalWidth\n",
    "        #y_lookback batch_size seq_length 1\n",
    "        #a batch_size seq_length 1\n",
    "\n",
    "        #flatten()会智能忽略batch_size维度\n",
    "        x_bar_flat = self.flatten(x_bar)# batch_size seq_length*temporalWidth\n",
    "        y_lookback = y_lookback.squeeze()#batch_size seq_length\n",
    "        a = a.squeeze()#batch_size seq_length\n",
    "\n",
    "        encoder_input = torch.cat((y_lookback,a,x_bar_flat),dim=0)\n",
    "        # encoder_input batch_size seq_length+seq_length+seq_length*temporalWidth\n",
    "        \n",
    "        dense_encoder = DenseEncoder(encoder_input.shape[-1],self.hiddenSize,self.hiddenSize//2,0.2,self.numEncoderLayers)\n",
    "        e = dense_encoder(encoder_input)\n",
    "        #e batch_size self.hiddenSize//2\n",
    "        dense_decoder = DenseDecoder(e.shape[-1],self.hiddenSize,self.H,self.decoderOutputDim,0.2,self.numDecoderLayers)\n",
    "        g = dense_decoder(e)\n",
    "        #g batch_size decoderOutputDim H\n",
    "        x_bar = x_bar.reshape(batch_size,self.decoderOutputDim,(seq_length*self.temporalWidth)//self.decoderOutputDim,-1)\n",
    "        x_bar = x_bar[:,:,-self.H:]\n",
    "        #x_bar batch_size decoderOutputDim H\n",
    "        temporal_decoder_input = torch.cat((g,x_bar),dim=1)\n",
    "        #temporal_decoder_input batch_size decoderOutputDim*2 H\n",
    "        feature_size = temporal_decoder_input.shape[-2];\n",
    "        temporal_decoder = TemporalDecoder(feature_size,(feature_size+self.temporalWidth)//2,self.temporalWidth,0.2)\n",
    "        for i in range(temporal_decoder_input.shape[-1]):\n",
    "            if(i==0):\n",
    "                y_bar = temporal_decoder(temporal_decoder_input[:,:,i].squeeze()).unsqueeze(dim=-1)\n",
    "            else:\n",
    "                y_bar = y_bar.concat(temporal_decoder(temporal_decoder_input[:,:,i].squeeze()).unsqueeze(dim=-1),dim=-1)\n",
    "        #y_bar batch_size 1 H\n",
    "        y_bar = y_bar.squeeze()\n",
    "        linear = nn.Linear(seq_length,self.H)\n",
    "        #y_lookback batch_size seq_length\n",
    "        y_lookback = linear(y_lookback)\n",
    "        output = y_lookback+y_bar\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
